{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kendal</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RecruitmentStrategy_1</th>\n",
       "      <td>0.571330</td>\n",
       "      <td>0.571330</td>\n",
       "      <td>0.571330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EducationLevel</th>\n",
       "      <td>0.214417</td>\n",
       "      <td>0.236710</td>\n",
       "      <td>0.230218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkillScore</th>\n",
       "      <td>0.167029</td>\n",
       "      <td>0.203668</td>\n",
       "      <td>0.203484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PersonalityScore</th>\n",
       "      <td>0.137927</td>\n",
       "      <td>0.169177</td>\n",
       "      <td>0.168043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InterviewScore</th>\n",
       "      <td>0.123372</td>\n",
       "      <td>0.146064</td>\n",
       "      <td>0.150309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExperienceYears</th>\n",
       "      <td>0.102202</td>\n",
       "      <td>0.122494</td>\n",
       "      <td>0.121406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreviousCompanies</th>\n",
       "      <td>0.039412</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.044063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.002249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistanceFromCompany</th>\n",
       "      <td>-0.013621</td>\n",
       "      <td>-0.016791</td>\n",
       "      <td>-0.016676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecruitmentStrategy_3</th>\n",
       "      <td>-0.173982</td>\n",
       "      <td>-0.173982</td>\n",
       "      <td>-0.173982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecruitmentStrategy_2</th>\n",
       "      <td>-0.385584</td>\n",
       "      <td>-0.385584</td>\n",
       "      <td>-0.385584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         kendal   pearson  spearman\n",
       "RecruitmentStrategy_1  0.571330  0.571330  0.571330\n",
       "EducationLevel         0.214417  0.236710  0.230218\n",
       "SkillScore             0.167029  0.203668  0.203484\n",
       "PersonalityScore       0.137927  0.169177  0.168043\n",
       "InterviewScore         0.123372  0.146064  0.150309\n",
       "ExperienceYears        0.102202  0.122494  0.121406\n",
       "PreviousCompanies      0.039412  0.044025  0.044063\n",
       "Age                    0.002075  0.001850  0.002500\n",
       "Gender                -0.002249 -0.002249 -0.002249\n",
       "DistanceFromCompany   -0.013621 -0.016791 -0.016676\n",
       "RecruitmentStrategy_3 -0.173982 -0.173982 -0.173982\n",
       "RecruitmentStrategy_2 -0.385584 -0.385584 -0.385584"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "recruitment = pd.read_csv('recruitment_data.csv', sep=',', decimal='.')\n",
    "\n",
    "\n",
    "# Instanciando o objeto One-Hot encoder, pois vai ser utilizada na coluna Recruitment Strategy\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "# Fazendo a transformação\n",
    "ohe_df = pd.DataFrame(ohe.fit_transform(recruitment[['RecruitmentStrategy']]).toarray(), columns=['RecruitmentStrategy_1','RecruitmentStrategy_2','RecruitmentStrategy_3'])\n",
    "\n",
    "# Agrupando a nova coluna com o df original\n",
    "df = recruitment.join(ohe_df)\n",
    "recruitment = df.drop(['RecruitmentStrategy'], axis=1)\n",
    "\n",
    "features = list(recruitment.columns.values)\n",
    "\n",
    "classificacao = 'HiringDecision'\n",
    "\n",
    "corrKendall = recruitment.corr('kendall')\n",
    "\n",
    "corrPearson = recruitment.corr('pearson')\n",
    "\n",
    "corrSpearman = recruitment.corr('spearman')\n",
    "\n",
    "tabela_correlacoes = pd.DataFrame()\n",
    "\n",
    "tabela_correlacoes['kendal']= corrKendall['HiringDecision'].sort_values(ascending=False)\n",
    "tabela_correlacoes['pearson']= corrPearson['HiringDecision'].sort_values(ascending=False)\n",
    "tabela_correlacoes['spearman']= corrSpearman['HiringDecision'].sort_values(ascending=False)\n",
    "\n",
    "tabela_correlacoes.drop(tabela_correlacoes[tabela_correlacoes['kendal']==1].index, inplace=True)\n",
    "#Verifica-se que a estrategia de recrutamento  =1 que eh a agressiva, vai impactar muito na decisao final de contratacao\n",
    "tabela_correlacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#removendo o sexo pois de acordo com o plot de distruicao , a chance de recrutamento eh equivalente para os dois sexos\n",
    "#removendo distancia da compania pq pela correlacao usando todos metodos, o resultado foi muito abaixo.\n",
    "features.remove('Gender')\n",
    "features.remove('DistanceFromCompany')\n",
    "\n",
    "#Remove o output\n",
    "features.remove(classificacao)\n",
    "\n",
    "X = recruitment[features].to_numpy() \n",
    "Y = recruitment[classificacao]\n",
    "\n",
    "# Normalizando as features X\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler = X_scaler.fit(X)\n",
    "X_normalizado_standard = X_scaler.transform(X)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X_normalizado_min_max = scaler.transform(X)\n",
    "#seaborn.scatterplot(X_normalizado_min_max) #melhor pois tem features que tem escala diferente \n",
    "\n",
    "\n",
    "\n",
    "# PARAMETROS DA REDE \n",
    "maximo_neuronios = 5\n",
    "funcao_ativacao = 'tanh' \n",
    "metrica = 'Accuracy' \n",
    "#quantidade de loops q vai esperar ate q o erro de teste comece a aumentar \n",
    "paciencia = 300\n",
    "max_epocas = 5*paciencia\n",
    "min_improvement = 0.01\n",
    "adam_initial_lr = 0.01\n",
    "adam_lr_decay = 0.99\n",
    "rollback_on_no_lower_bound_gain = True #se comecar o erro a subir, volta pra onde tava bom\n",
    "\n",
    "# SEED que controla a aleatoriedade \n",
    "random_seed = 22\n",
    "n_k_folds = 5 #quantas partes o dataset vai ser dividido\n",
    "keras.utils.set_random_seed(random_seed)\n",
    "# DIVIDE EM K PEDACOS\n",
    "sk_folds = StratifiedKFold(n_splits=n_k_folds)\n",
    "sk_folds.get_n_splits(X_normalizado_min_max, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAM-N1F1_RecruitmentStrategy_3 > epochs: 566 loss: 0.0017717911396175623 val_loss: 0.0016852682456374168 Accuracy: 100.0% val_Accuracy: 100.0%\n",
      "ADAM-N2F1_RecruitmentStrategy_3 > epochs: 528 loss: 0.0021910679060965776 val_loss: 0.002174674067646265 Accuracy: 100.0% val_Accuracy: 100.0%\n",
      "ADAM-N3F1_RecruitmentStrategy_3 > epochs: 364 loss: 0.000555908540263772 val_loss: 0.0005406267009675503 Accuracy: 100.0% val_Accuracy: 100.0%\n",
      "ADAM-N4F1_RecruitmentStrategy_3 > epochs: 343 loss: 0.0007782704196870327 val_loss: 0.0008650257368572056 Accuracy: 100.0% val_Accuracy: 100.0%\n",
      "ADAM-N5F1_RecruitmentStrategy_3 > epochs: 316 loss: 0.0004115051415283233 val_loss: 0.0003974048886448145 Accuracy: 100.0% val_Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# TREINANDO\n",
    "metric_lower_bound = 0.0\n",
    "metric_median = 0.0\n",
    "resultados = []\n",
    "for n_neuron in numpy.arange(1, maximo_neuronios+1):\n",
    "    ix_fold = 1\n",
    "    #divisao os grupos de treino e teste, ele faz pelos indices\n",
    "    for train_index, test_index in sk_folds.split(X_normalizado_min_max, Y):\n",
    "        # pegar o dado do teste  e treino   a partir dos indices da divisao feita pelo skfolds\n",
    "        X_train, X_test = X_normalizado_min_max[train_index], X_normalizado_min_max[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        #configurando o otimizador \n",
    "        optimizer = keras.optimizers.Adam( learning_rate=adam_initial_lr, \n",
    "                                                  beta_1=adam_lr_decay ) \n",
    "        \n",
    "        # Configurando a rede\n",
    "        model_name = f\"ADAM-N{n_neuron}F{ix_fold}_{classificacao}\"\n",
    "        val_metric_name = f'val_{metrica}'\n",
    "        \n",
    "        inputs = keras.Input(shape=(len(features), ))\n",
    "        hidden = keras.layers.Dense(n_neuron, activation=funcao_ativacao)(inputs)\n",
    "        outputs = keras.layers.Dense(1, activation=funcao_ativacao)(hidden) #penas 1 classificacao = 1 saida\n",
    "        rede = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "        #Usar o otimizador com erro medio quadratico \n",
    "        rede.compile(optimizer=optimizer, loss='mse', metrics=[metrica])\n",
    "        \n",
    "        #early stop com foco no erro do grupo de validacao\n",
    "        es_loss = keras.callbacks.EarlyStopping(monitor='val_loss', patience=paciencia, restore_best_weights=True)\n",
    "        #early stop com foco na acuracia dos testes\n",
    "        es_metric = keras.callbacks.EarlyStopping(monitor=metrica, mode='max', patience=paciencia, min_delta=min_improvement, restore_best_weights=True)\n",
    "\n",
    "\n",
    "        #iniciando a rede para tentar encontrar o modelo\n",
    "        resultado = rede.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=X_train.shape[0], \n",
    "                                epochs=max_epocas, verbose=0, callbacks=[es_loss, es_metric])\n",
    "\n",
    "    \n",
    "\n",
    "        # RESULTADOS DA REDE\n",
    "        model_loss = resultado.history['loss'][-1]\n",
    "        model_val_loss = resultado.history['val_loss'][-1]\n",
    "        metric_val = resultado.history[metrica][-1]\n",
    "        val_metric_val = resultado.history[val_metric_name][-1]\n",
    "        n_epochs = len(resultado.history['val_loss'])\n",
    "\n",
    "        resultado_dict = {'model_name': model_name,\n",
    "                        'optimizer': optimizer,\n",
    "                        'neurons': n_neuron,\n",
    "                        'fold': ix_fold,\n",
    "                        'loss': model_loss,\n",
    "                        'val_loss': model_val_loss,\n",
    "                        metrica: metric_val,\n",
    "                        val_metric_name: val_metric_val,\n",
    "                        'epochs': n_epochs,\n",
    "                        'net': rede,\n",
    "                        'history': resultado}\n",
    "        resultados.append(resultado_dict)\n",
    "\n",
    "        print(f\"{model_name} > epochs: {n_epochs} loss: {model_loss} val_loss: {model_val_loss} {metrica}: {100.0*metric_val}% {val_metric_name}: {100.0*val_metric_val}%\")\n",
    "              \n",
    "\n",
    "        # SE CHEGAR NO 100% para de aumentar \n",
    "        maximized_metrics = (val_metric_val == 1.0) & (metric_val == 1.0)\n",
    "\n",
    "        if maximized_metrics:\n",
    "            break\n",
    "\n",
    "        print('')\n",
    "        ix_fold += 1\n",
    "        \n",
    "    # GET LOWER BOUND OF WINNING ALGORITHM\n",
    "    df_resultados = pd.DataFrame(resultados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

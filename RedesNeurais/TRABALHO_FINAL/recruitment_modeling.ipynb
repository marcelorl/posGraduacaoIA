{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "recrutamento = pd.read_csv('recruitment_data.csv', sep=',', decimal='.')\n",
    "\n",
    "\n",
    "# Instanciando o objeto One-Hot encoder, pois vai ser utilizada na coluna recrutamento Strategy\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "# Fazendo a transformação\n",
    "ohe_df = pd.DataFrame(ohe.fit_transform(recrutamento[['RecruitmentStrategy']]).toarray(), columns=['RecruitmentStrategy_1','RecruitmentStrategy_2','RecruitmentStrategy_3'])\n",
    "\n",
    "# Agrupando a nova coluna com o df original\n",
    "df = recrutamento.join(ohe_df)\n",
    "\n",
    "recrutamento = df.drop(['RecruitmentStrategy'], axis=1)\n",
    "\n",
    "features = list(recrutamento.columns.values)\n",
    "\n",
    "classificacao = 'HiringDecision'\n",
    "\n",
    "corrKendall = recrutamento.corr('kendall')\n",
    "\n",
    "corrPearson = recrutamento.corr('pearson')\n",
    "\n",
    "corrSpearman = recrutamento.corr('spearman')\n",
    "\n",
    "tabela_correlacoes = pd.DataFrame()\n",
    "\n",
    "tabela_correlacoes['kendal']= corrKendall['HiringDecision'].sort_values(ascending=False)\n",
    "tabela_correlacoes['pearson']= corrPearson['HiringDecision'].sort_values(ascending=False)\n",
    "tabela_correlacoes['spearman']= corrSpearman['HiringDecision'].sort_values(ascending=False)\n",
    "\n",
    "tabela_correlacoes.drop(tabela_correlacoes[tabela_correlacoes['kendal']==1].index, inplace=True)\n",
    "#Verifica-se que a estrategia de recrutamento  =1 que eh a agressiva, vai impactar muito na decisao final de contratacao\n",
    "\n",
    "#removendo as features que tiveram indice de correlacao menor que 0.1\n",
    "#tabela_correlacoes[tabela_correlacoes['kendal']<0.1].index\n",
    "\n",
    "#relacoes_excluidas = tabela_correlacoes[tabela_correlacoes['kendal']<0.1].index\n",
    "\n",
    "#features = [i for i in features if i not in relacoes_excluidas]\n",
    "\n",
    "features.remove('PreviousCompanies')\n",
    "features.remove('Age')\n",
    "features.remove('Gender')\n",
    "features.remove('DistanceFromCompany')\n",
    "#Remove o output\n",
    "features.remove(classificacao)\n",
    "\n",
    "X = recrutamento[features].to_numpy() \n",
    "Y = recrutamento[classificacao].to_numpy() \n",
    "\n",
    "\n",
    "# Normalizando as features X\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler = X_scaler.fit(X)\n",
    "X_normalizado_standard = X_scaler.transform(X)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X_normalizado_min_max = scaler.transform(X)\n",
    "\n",
    "\n",
    "X_transformado= X_normalizado_standard\n",
    "\n",
    "#Testando usando PCA\n",
    "# pca = PCA(n_components=3)\n",
    "# pca.fit(X)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.singular_values_)\n",
    "\n",
    "# X_transformado = pca.fit_transform(X= X_transformado)\n",
    "\n",
    "\n",
    "#seaborn.scatterplot(X_normalizado_min_max) #melhor pois tem features que tem escala diferente \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETROS DA REDE \n",
    "maximo_neuronios = 5\n",
    "funcoes_ativacao = ['tanh', 'relu', 'sigmoid'] \n",
    "metrica = 'Accuracy' \n",
    "#quantidade de loops q vai esperar ate q o erro de teste comece a aumentar \n",
    "paciencia = 150\n",
    "max_epocas =3*paciencia\n",
    "min_improvement = 0.01\n",
    "adam_initial_lr = 0.01\n",
    "adam_lr_decay = 0.99\n",
    "rollback_on_no_lower_bound_gain = True #se comecar o erro a subir, volta pra onde tava bom\n",
    "\n",
    "# SEED que controla a aleatoriedade \n",
    "random_seed = 22\n",
    "n_k_folds = 5 #quantas partes o dataset vai ser dividido\n",
    "keras.utils.set_random_seed(random_seed)\n",
    "# DIVIDE EM K PEDACOS\n",
    "sk_folds = StratifiedKFold(n_splits=n_k_folds)\n",
    "sk_folds.get_n_splits(X_transformado, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAM-N1F1_HiringDecision_tanh > epochs: 392 loss: 0.10504956543445587 val_loss: 0.0714852437376976 Accuracy: 86.75000071525574% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N1F1_HiringDecision_relu > epochs: 264 loss: 0.10250194370746613 val_loss: 0.07032917439937592 Accuracy: 86.75000071525574% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N1F1_HiringDecision_sigmoid > epochs: 151 loss: 0.16054551303386688 val_loss: 0.14875398576259613 Accuracy: 68.99999976158142% val_Accuracy: 68.99999976158142%\n",
      "\n",
      "ADAM-N1F2_HiringDecision_tanh > epochs: 243 loss: 0.10318708419799805 val_loss: 0.0702579990029335 Accuracy: 86.75000071525574% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N1F2_HiringDecision_relu > epochs: 183 loss: 0.10426127910614014 val_loss: 0.08623228967189789 Accuracy: 87.00000047683716% val_Accuracy: 88.99999856948853%\n",
      "\n",
      "ADAM-N1F2_HiringDecision_sigmoid > epochs: 196 loss: 0.17782056331634521 val_loss: 0.16947482526302338 Accuracy: 68.99999976158142% val_Accuracy: 68.99999976158142%\n",
      "\n",
      "ADAM-N1F3_HiringDecision_tanh > epochs: 418 loss: 0.10320323705673218 val_loss: 0.06993871927261353 Accuracy: 87.58333325386047% val_Accuracy: 91.66666865348816%\n",
      "\n",
      "ADAM-N1F3_HiringDecision_relu > epochs: 379 loss: 0.10503990948200226 val_loss: 0.07048361748456955 Accuracy: 86.66666746139526% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N1F3_HiringDecision_sigmoid > epochs: 210 loss: 0.15293848514556885 val_loss: 0.14087417721748352 Accuracy: 68.99999976158142% val_Accuracy: 68.99999976158142%\n",
      "\n",
      "ADAM-N1F4_HiringDecision_tanh > epochs: 423 loss: 0.10241913795471191 val_loss: 0.07620753347873688 Accuracy: 87.41666674613953% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N1F4_HiringDecision_relu > epochs: 377 loss: 0.09994573891162872 val_loss: 0.07301278412342072 Accuracy: 88.08333277702332% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N1F4_HiringDecision_sigmoid > epochs: 164 loss: 0.18783830106258392 val_loss: 0.18351514637470245 Accuracy: 68.99999976158142% val_Accuracy: 68.99999976158142%\n",
      "\n",
      "ADAM-N1F5_HiringDecision_tanh > epochs: 215 loss: 0.07200019806623459 val_loss: 0.21629221737384796 Accuracy: 89.83333110809326% val_Accuracy: 72.33333587646484%\n",
      "\n",
      "ADAM-N1F5_HiringDecision_relu > epochs: 258 loss: 0.07032834738492966 val_loss: 0.20705723762512207 Accuracy: 90.66666960716248% val_Accuracy: 72.66666889190674%\n",
      "\n",
      "ADAM-N1F5_HiringDecision_sigmoid > epochs: 267 loss: 0.07250627875328064 val_loss: 0.19694852828979492 Accuracy: 90.58333039283752% val_Accuracy: 73.33333492279053%\n",
      "\n",
      "ADAM-N2F1_HiringDecision_tanh > epochs: 289 loss: 0.10177821666002274 val_loss: 0.07078626751899719 Accuracy: 86.91666722297668% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N2F1_HiringDecision_relu > epochs: 217 loss: 0.10067018866539001 val_loss: 0.0624995231628418 Accuracy: 87.33333349227905% val_Accuracy: 92.66666769981384%\n",
      "\n",
      "ADAM-N2F1_HiringDecision_sigmoid > epochs: 340 loss: 0.10334698855876923 val_loss: 0.07253194600343704 Accuracy: 86.75000071525574% val_Accuracy: 89.66666460037231%\n",
      "\n",
      "ADAM-N2F2_HiringDecision_tanh > epochs: 197 loss: 0.10336726903915405 val_loss: 0.07162746042013168 Accuracy: 86.58333420753479% val_Accuracy: 91.33333563804626%\n",
      "\n",
      "ADAM-N2F2_HiringDecision_relu > epochs: 403 loss: 0.09904127568006516 val_loss: 0.07020696997642517 Accuracy: 88.16666603088379% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N2F2_HiringDecision_sigmoid > epochs: 273 loss: 0.10306107252836227 val_loss: 0.07773877680301666 Accuracy: 86.33333444595337% val_Accuracy: 89.66666460037231%\n",
      "\n",
      "ADAM-N2F3_HiringDecision_tanh > epochs: 279 loss: 0.10257294774055481 val_loss: 0.07003824412822723 Accuracy: 87.58333325386047% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N2F3_HiringDecision_relu > epochs: 357 loss: 0.10174168646335602 val_loss: 0.06603232771158218 Accuracy: 87.41666674613953% val_Accuracy: 91.66666865348816%\n",
      "\n",
      "ADAM-N2F3_HiringDecision_sigmoid > epochs: 450 loss: 0.09867476671934128 val_loss: 0.06638484448194504 Accuracy: 87.41666674613953% val_Accuracy: 91.33333563804626%\n",
      "\n",
      "ADAM-N2F4_HiringDecision_tanh > epochs: 439 loss: 0.10280603915452957 val_loss: 0.07517386227846146 Accuracy: 87.41666674613953% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N2F4_HiringDecision_relu > epochs: 245 loss: 0.10174070298671722 val_loss: 0.07577410340309143 Accuracy: 87.00000047683716% val_Accuracy: 91.66666865348816%\n",
      "\n",
      "ADAM-N2F4_HiringDecision_sigmoid > epochs: 316 loss: 0.10070762783288956 val_loss: 0.0724702998995781 Accuracy: 87.58333325386047% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N2F5_HiringDecision_tanh > epochs: 184 loss: 0.06632577627897263 val_loss: 0.21605271100997925 Accuracy: 91.66666865348816% val_Accuracy: 73.66666793823242%\n",
      "\n",
      "ADAM-N2F5_HiringDecision_relu > epochs: 177 loss: 0.08712498843669891 val_loss: 0.21046486496925354 Accuracy: 89.99999761581421% val_Accuracy: 74.00000095367432%\n",
      "\n",
      "ADAM-N2F5_HiringDecision_sigmoid > epochs: 336 loss: 0.0895409807562828 val_loss: 0.19327642023563385 Accuracy: 90.41666388511658% val_Accuracy: 71.66666388511658%\n",
      "\n",
      "ADAM-N3F1_HiringDecision_tanh > epochs: 283 loss: 0.10145267844200134 val_loss: 0.06653847545385361 Accuracy: 87.58333325386047% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N3F1_HiringDecision_relu > epochs: 395 loss: 0.10092132538557053 val_loss: 0.06864848732948303 Accuracy: 86.50000095367432% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N3F1_HiringDecision_sigmoid > epochs: 263 loss: 0.10393360257148743 val_loss: 0.07326982915401459 Accuracy: 86.41666769981384% val_Accuracy: 89.66666460037231%\n",
      "\n",
      "ADAM-N3F2_HiringDecision_tanh > epochs: 178 loss: 0.10132833570241928 val_loss: 0.07432688027620316 Accuracy: 86.91666722297668% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N3F2_HiringDecision_relu > epochs: 344 loss: 0.09892607480287552 val_loss: 0.07628470659255981 Accuracy: 87.5% val_Accuracy: 89.33333158493042%\n",
      "\n",
      "ADAM-N3F2_HiringDecision_sigmoid > epochs: 333 loss: 0.10210799425840378 val_loss: 0.07732705771923065 Accuracy: 86.33333444595337% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N3F3_HiringDecision_tanh > epochs: 230 loss: 0.10280078649520874 val_loss: 0.0701540857553482 Accuracy: 86.83333396911621% val_Accuracy: 91.00000262260437%\n",
      "\n",
      "ADAM-N3F3_HiringDecision_relu > epochs: 165 loss: 0.14274275302886963 val_loss: 0.12099575251340866 Accuracy: 69.16666626930237% val_Accuracy: 68.99999976158142%\n",
      "\n",
      "ADAM-N3F3_HiringDecision_sigmoid > epochs: 267 loss: 0.10589650273323059 val_loss: 0.07323887199163437 Accuracy: 86.00000143051147% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N3F4_HiringDecision_tanh > epochs: 338 loss: 0.09947455674409866 val_loss: 0.07197830080986023 Accuracy: 87.33333349227905% val_Accuracy: 89.33333158493042%\n",
      "\n",
      "ADAM-N3F4_HiringDecision_relu > epochs: 327 loss: 0.10061266273260117 val_loss: 0.07105634361505508 Accuracy: 87.58333325386047% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N3F4_HiringDecision_sigmoid > epochs: 289 loss: 0.10249079018831253 val_loss: 0.07074619829654694 Accuracy: 86.75000071525574% val_Accuracy: 92.33333468437195%\n",
      "\n",
      "ADAM-N3F5_HiringDecision_tanh > epochs: 223 loss: 0.06787888705730438 val_loss: 0.22057555615901947 Accuracy: 90.83333611488342% val_Accuracy: 73.33333492279053%\n",
      "\n",
      "ADAM-N3F5_HiringDecision_relu > epochs: 290 loss: 0.06842709332704544 val_loss: 0.2179594188928604 Accuracy: 91.25000238418579% val_Accuracy: 73.66666793823242%\n",
      "\n",
      "ADAM-N3F5_HiringDecision_sigmoid > epochs: 281 loss: 0.07141189277172089 val_loss: 0.21197877824306488 Accuracy: 90.24999737739563% val_Accuracy: 72.66666889190674%\n",
      "\n",
      "ADAM-N4F1_HiringDecision_tanh > epochs: 198 loss: 0.10293332487344742 val_loss: 0.0676346942782402 Accuracy: 86.91666722297668% val_Accuracy: 91.66666865348816%\n",
      "\n",
      "ADAM-N4F1_HiringDecision_relu > epochs: 211 loss: 0.10556060075759888 val_loss: 0.0731009766459465 Accuracy: 86.2500011920929% val_Accuracy: 88.66666555404663%\n",
      "\n",
      "ADAM-N4F1_HiringDecision_sigmoid > epochs: 270 loss: 0.10097331553697586 val_loss: 0.06431959569454193 Accuracy: 87.1666669845581% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N4F2_HiringDecision_tanh > epochs: 233 loss: 0.09960944950580597 val_loss: 0.07584816217422485 Accuracy: 87.33333349227905% val_Accuracy: 88.66666555404663%\n",
      "\n",
      "ADAM-N4F2_HiringDecision_relu > epochs: 333 loss: 0.09931309521198273 val_loss: 0.07447556406259537 Accuracy: 88.16666603088379% val_Accuracy: 89.66666460037231%\n",
      "\n",
      "ADAM-N4F2_HiringDecision_sigmoid > epochs: 256 loss: 0.10164155811071396 val_loss: 0.0744483694434166 Accuracy: 86.91666722297668% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N4F3_HiringDecision_tanh > epochs: 359 loss: 0.09088566154241562 val_loss: 0.05903719738125801 Accuracy: 88.58333230018616% val_Accuracy: 91.66666865348816%\n",
      "\n",
      "ADAM-N4F3_HiringDecision_relu > epochs: 231 loss: 0.10021551698446274 val_loss: 0.06430993229150772 Accuracy: 87.5% val_Accuracy: 91.00000262260437%\n",
      "\n",
      "ADAM-N4F3_HiringDecision_sigmoid > epochs: 318 loss: 0.10438123345375061 val_loss: 0.07190603762865067 Accuracy: 85.916668176651% val_Accuracy: 91.33333563804626%\n",
      "\n",
      "ADAM-N4F4_HiringDecision_tanh > epochs: 283 loss: 0.10098066926002502 val_loss: 0.07280699908733368 Accuracy: 87.25000023841858% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N4F4_HiringDecision_relu > epochs: 217 loss: 0.10154903680086136 val_loss: 0.07257861644029617 Accuracy: 87.66666650772095% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N4F4_HiringDecision_sigmoid > epochs: 258 loss: 0.10324762761592865 val_loss: 0.07205192744731903 Accuracy: 86.58333420753479% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N4F5_HiringDecision_tanh > epochs: 207 loss: 0.06598401069641113 val_loss: 0.22398754954338074 Accuracy: 91.58333539962769% val_Accuracy: 73.66666793823242%\n",
      "\n",
      "ADAM-N4F5_HiringDecision_relu > epochs: 173 loss: 0.0624622143805027 val_loss: 0.2252136766910553 Accuracy: 91.75000190734863% val_Accuracy: 74.33333396911621%\n",
      "\n",
      "ADAM-N4F5_HiringDecision_sigmoid > epochs: 183 loss: 0.06568357348442078 val_loss: 0.21615414321422577 Accuracy: 91.00000262260437% val_Accuracy: 73.00000190734863%\n",
      "\n",
      "ADAM-N5F1_HiringDecision_tanh > epochs: 242 loss: 0.0980033427476883 val_loss: 0.06835424154996872 Accuracy: 87.33333349227905% val_Accuracy: 89.33333158493042%\n",
      "\n",
      "ADAM-N5F1_HiringDecision_relu > epochs: 261 loss: 0.09992195665836334 val_loss: 0.06571394205093384 Accuracy: 87.5% val_Accuracy: 92.33333468437195%\n",
      "\n",
      "ADAM-N5F1_HiringDecision_sigmoid > epochs: 284 loss: 0.10270652174949646 val_loss: 0.07355587184429169 Accuracy: 86.50000095367432% val_Accuracy: 89.99999761581421%\n",
      "\n",
      "ADAM-N5F2_HiringDecision_tanh > epochs: 256 loss: 0.09292756766080856 val_loss: 0.06968025863170624 Accuracy: 88.58333230018616% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N5F2_HiringDecision_relu > epochs: 206 loss: 0.10301326960325241 val_loss: 0.08035658299922943 Accuracy: 87.25000023841858% val_Accuracy: 88.66666555404663%\n",
      "\n",
      "ADAM-N5F2_HiringDecision_sigmoid > epochs: 344 loss: 0.0999150276184082 val_loss: 0.07199358195066452 Accuracy: 86.58333420753479% val_Accuracy: 90.3333306312561%\n",
      "\n",
      "ADAM-N5F3_HiringDecision_tanh > epochs: 174 loss: 0.10328753292560577 val_loss: 0.06899093836545944 Accuracy: 87.25000023841858% val_Accuracy: 92.00000166893005%\n",
      "\n",
      "ADAM-N5F3_HiringDecision_relu > epochs: 384 loss: 0.09308532625436783 val_loss: 0.06237906590104103 Accuracy: 88.24999928474426% val_Accuracy: 91.00000262260437%\n",
      "\n",
      "ADAM-N5F3_HiringDecision_sigmoid > epochs: 242 loss: 0.10087074339389801 val_loss: 0.06861316412687302 Accuracy: 86.83333396911621% val_Accuracy: 90.66666960716248%\n",
      "\n",
      "ADAM-N5F4_HiringDecision_tanh > epochs: 201 loss: 0.09987902641296387 val_loss: 0.07167162001132965 Accuracy: 87.5% val_Accuracy: 88.66666555404663%\n",
      "\n",
      "ADAM-N5F4_HiringDecision_relu > epochs: 198 loss: 0.09574375301599503 val_loss: 0.06699902564287186 Accuracy: 87.99999952316284% val_Accuracy: 91.00000262260437%\n",
      "\n",
      "ADAM-N5F4_HiringDecision_sigmoid > epochs: 450 loss: 0.09575733542442322 val_loss: 0.06364286690950394 Accuracy: 88.16666603088379% val_Accuracy: 91.00000262260437%\n",
      "\n",
      "ADAM-N5F5_HiringDecision_tanh > epochs: 204 loss: 0.06350512057542801 val_loss: 0.21830756962299347 Accuracy: 91.33333563804626% val_Accuracy: 74.00000095367432%\n",
      "\n",
      "ADAM-N5F5_HiringDecision_relu > epochs: 176 loss: 0.06280814111232758 val_loss: 0.22218534350395203 Accuracy: 91.75000190734863% val_Accuracy: 74.33333396911621%\n",
      "\n",
      "ADAM-N5F5_HiringDecision_sigmoid > epochs: 211 loss: 0.06613139063119888 val_loss: 0.21837890148162842 Accuracy: 91.08333587646484% val_Accuracy: 73.66666793823242%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TREINANDO\n",
    "metric_lower_bound = 0.0\n",
    "metric_median = 0.0\n",
    "resultados = []\n",
    "for n_neuron in numpy.arange(1, maximo_neuronios+1):\n",
    "    ix_fold = 1\n",
    "    #divisao os grupos de treino e teste, ele faz pelos indices\n",
    "    for train_index, test_index in sk_folds.split(X_transformado, Y):\n",
    "        # pegar o dado do teste  e treino   a partir dos indices da divisao feita pelo skfolds\n",
    "        X_train, X_test = X_transformado[train_index], X_transformado[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        for funcao_ativacao in funcoes_ativacao : \n",
    "            #configurando o otimizador \n",
    "            optimizer = keras.optimizers.Adam( learning_rate=adam_initial_lr, \n",
    "                                                    beta_1=adam_lr_decay ) \n",
    "            \n",
    "            # Configurando a rede\n",
    "            model_name = f\"ADAM-N{n_neuron}F{ix_fold}_{classificacao}_{funcao_ativacao}\"\n",
    "            val_metric_name = f'val_{metrica}'\n",
    "            \n",
    "            inputs = keras.Input(shape=(X_transformado.shape[1], ))        \n",
    "            hidden = keras.layers.Dense(n_neuron, activation=funcao_ativacao)(inputs)\n",
    "            outputs = keras.layers.Dense(1, activation='sigmoid')(hidden) #penas 1 classificacao = 1 saida\n",
    "            rede = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "            #Usar o otimizador com erro medio quadratico \n",
    "            rede.compile(optimizer=optimizer, loss='mse', metrics=[metrica])\n",
    "            \n",
    "            #early stop com foco no erro do grupo de validacao\n",
    "            es_loss = keras.callbacks.EarlyStopping(monitor='val_loss', patience=paciencia, restore_best_weights=True)\n",
    "            #early stop com foco na acuracia dos testes\n",
    "            es_metric = keras.callbacks.EarlyStopping(monitor=metrica, mode='max', patience=paciencia, min_delta=min_improvement, restore_best_weights=True)\n",
    "\n",
    "\n",
    "            #iniciando a rede para tentar encontrar o modelo\n",
    "            resultado = rede.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=X_train.shape[0], \n",
    "                                    epochs=max_epocas, verbose=0, callbacks=[es_loss, es_metric])\n",
    "\n",
    "        \n",
    "\n",
    "            # RESULTADOS DA REDE\n",
    "            model_loss = resultado.history['loss'][-1]\n",
    "            model_val_loss = resultado.history['val_loss'][-1]\n",
    "            metric_val = resultado.history[metrica][-1]\n",
    "            val_metric_val = resultado.history[val_metric_name][-1]\n",
    "            n_epochs = len(resultado.history['val_loss'])\n",
    "\n",
    "            resultado_dict = {'model_name': model_name,\n",
    "                            'optimizer': optimizer,\n",
    "                            'neurons': n_neuron,\n",
    "                            'fold': ix_fold,\n",
    "                            'loss': model_loss,\n",
    "                            'val_loss': model_val_loss,\n",
    "                            metrica: metric_val,\n",
    "                            val_metric_name: val_metric_val,\n",
    "                            'epochs': n_epochs,\n",
    "                            'net': rede,\n",
    "                            'history': resultado}\n",
    "            resultados.append(resultado_dict)\n",
    "\n",
    "            print(f\"{model_name} > epochs: {n_epochs} loss: {model_loss} val_loss: {model_val_loss} {metrica}: {100.0*metric_val}% {val_metric_name}: {100.0*val_metric_val}%\")\n",
    "                \n",
    "\n",
    "            # SE CHEGAR NO 100% para de aumentar \n",
    "            maximized_metrics = (val_metric_val == 1.0) & (metric_val == 1.0)\n",
    "\n",
    "            if maximized_metrics:\n",
    "                break\n",
    "\n",
    "            print('')\n",
    "        ix_fold += 1\n",
    "        \n",
    "    # GET LOWER BOUND OF WINNING ALGORITHM\n",
    "    df_resultados = pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuronios</th>\n",
       "      <th>ativacao</th>\n",
       "      <th>Accuracy_media</th>\n",
       "      <th>val_Accuracy_media</th>\n",
       "      <th>epocas_media</th>\n",
       "      <th>val_loss_media</th>\n",
       "      <th>loss_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>0.874667</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.099527</td>\n",
       "      <td>0.090914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>215.4</td>\n",
       "      <td>0.099401</td>\n",
       "      <td>0.091521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.872667</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.099863</td>\n",
       "      <td>0.092079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.101936</td>\n",
       "      <td>0.093820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.880333</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>277.6</td>\n",
       "      <td>0.100736</td>\n",
       "      <td>0.095370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.879833</td>\n",
       "      <td>0.880667</td>\n",
       "      <td>279.8</td>\n",
       "      <td>0.096996</td>\n",
       "      <td>0.098064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>250.4</td>\n",
       "      <td>0.100715</td>\n",
       "      <td>0.094587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>292.2</td>\n",
       "      <td>0.101423</td>\n",
       "      <td>0.096415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.871333</td>\n",
       "      <td>306.2</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.093076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.096480</td>\n",
       "      <td>0.099066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>338.2</td>\n",
       "      <td>0.100836</td>\n",
       "      <td>0.097172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.875167</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>0.095185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>286.6</td>\n",
       "      <td>0.101312</td>\n",
       "      <td>0.097168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.825333</td>\n",
       "      <td>304.2</td>\n",
       "      <td>0.110989</td>\n",
       "      <td>0.102326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.733167</td>\n",
       "      <td>0.698667</td>\n",
       "      <td>197.6</td>\n",
       "      <td>0.167913</td>\n",
       "      <td>0.150330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neuronios ativacao  Accuracy_media  val_Accuracy_media  epocas_media  \\\n",
       "13          5     relu        0.885500            0.874667         245.0   \n",
       "12          5     tanh        0.884000            0.868667         215.4   \n",
       "9           4     tanh        0.883333            0.872667         256.0   \n",
       "10          4     relu        0.882667            0.868667         233.0   \n",
       "3           2     tanh        0.880333            0.873333         277.6   \n",
       "4           2     relu        0.879833            0.880667         279.8   \n",
       "6           3     tanh        0.879000            0.868667         250.4   \n",
       "1           1     relu        0.878333            0.866667         292.2   \n",
       "14          5  sigmoid        0.878333            0.871333         306.2   \n",
       "5           2  sigmoid        0.877000            0.865333         343.0   \n",
       "0           1     tanh        0.876667            0.870000         338.2   \n",
       "11          4  sigmoid        0.875167            0.869333         257.0   \n",
       "8           3  sigmoid        0.871500            0.872000         286.6   \n",
       "7           3     relu        0.844000            0.825333         304.2   \n",
       "2           1  sigmoid        0.733167            0.698667         197.6   \n",
       "\n",
       "    val_loss_media  loss_media  \n",
       "13        0.099527    0.090914  \n",
       "12        0.099401    0.091521  \n",
       "9         0.099863    0.092079  \n",
       "10        0.101936    0.093820  \n",
       "3         0.100736    0.095370  \n",
       "4         0.096996    0.098064  \n",
       "6         0.100715    0.094587  \n",
       "1         0.101423    0.096415  \n",
       "14        0.099237    0.093076  \n",
       "5         0.096480    0.099066  \n",
       "0         0.100836    0.097172  \n",
       "11        0.099776    0.095185  \n",
       "8         0.101312    0.097168  \n",
       "7         0.110989    0.102326  \n",
       "2         0.167913    0.150330  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_resumido = pd.DataFrame()\n",
    "\n",
    "lista_dict = []\n",
    "for qtde_neuronio in numpy.arange(1, maximo_neuronios+1):\n",
    "    for funcao_ativacao in funcoes_ativacao:\n",
    "        filtrado = df_resultados[(df_resultados['neurons']==qtde_neuronio) & (df_resultados['model_name'].str.contains(funcao_ativacao))]\n",
    "        temp_dict ={}\n",
    "        temp_dict['neuronios'] = qtde_neuronio\n",
    "        temp_dict['ativacao'] = funcao_ativacao\n",
    "        temp_dict[f'{metrica}_media'] =  filtrado.loc[:, metrica].mean()\n",
    "        stringVal = f'val_{metrica}'\n",
    "        temp_dict[f'{stringVal}_media'] =  filtrado.loc[:, stringVal].mean()\n",
    "        temp_dict[f'epocas_media'] =  filtrado.loc[:, 'epochs'].mean()\n",
    "        temp_dict[f'val_loss_media'] =  filtrado.loc[:, 'val_loss'].mean()\n",
    "        temp_dict[f'loss_media'] =  filtrado.loc[:, 'loss'].mean()\n",
    "        lista_dict.append(temp_dict)\n",
    "        \n",
    "\n",
    "resultado_resumido = pd.DataFrame(lista_dict)\n",
    "resultado_resumido.sort_values(by=f'{metrica}_media', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
